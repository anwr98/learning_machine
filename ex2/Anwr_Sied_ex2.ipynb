{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#https://github.com/anwr98/learning_machine.git"
      ],
      "metadata": {
        "id": "WCrxskDttjoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "HQ8qwDXKp4oB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Preprocess Data"
      ],
      "metadata": {
        "id": "EOjOoEC8p5xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# טעינת הנתונים של MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# נרמול הנתונים לטווח 0-1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# המרת התוויות ל-one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "_6ae-bo7p_pC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the Model"
      ],
      "metadata": {
        "id": "rrzQiruKqF7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(2, activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(71, activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(6, activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# שכבת הפלט (10 קטגוריות, אחת לכל ספרה)\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "W0uxuCsSqIvz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile the Model"
      ],
      "metadata": {
        "id": "N8a3NXvZqYui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iERjctUOqaGz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the Model"
      ],
      "metadata": {
        "id": "girtnWB3qgQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53aU0bObdOqc",
        "outputId": "63ea7c16-c671-480d-e003-4045a77c5c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.4724 - loss: 1.4386 - val_accuracy: 0.8274 - val_loss: 0.6765\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.7600 - val_accuracy: 0.8585 - val_loss: 0.5695\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.6455 - val_accuracy: 0.8772 - val_loss: 0.4952\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.5807 - val_accuracy: 0.8874 - val_loss: 0.4635\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.5470 - val_accuracy: 0.8756 - val_loss: 0.4996\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.5162 - val_accuracy: 0.8690 - val_loss: 0.4869\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.4920 - val_accuracy: 0.8886 - val_loss: 0.4428\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.4741 - val_accuracy: 0.8982 - val_loss: 0.4032\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.4505 - val_accuracy: 0.9018 - val_loss: 0.3983\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.4328 - val_accuracy: 0.8786 - val_loss: 0.4667\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.4346 - val_accuracy: 0.8909 - val_loss: 0.4274\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.4184 - val_accuracy: 0.8850 - val_loss: 0.4458\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.4227 - val_accuracy: 0.8941 - val_loss: 0.4063\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.3956 - val_accuracy: 0.8957 - val_loss: 0.4116\n",
            "Epoch 15/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.4005 - val_accuracy: 0.9003 - val_loss: 0.4071\n",
            "Epoch 16/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.3946 - val_accuracy: 0.8689 - val_loss: 0.4759\n",
            "Epoch 17/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.3863 - val_accuracy: 0.8632 - val_loss: 0.4770\n",
            "Epoch 18/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.3869 - val_accuracy: 0.8897 - val_loss: 0.4160\n",
            "Epoch 19/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.3749 - val_accuracy: 0.8131 - val_loss: 0.5880\n",
            "Epoch 20/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.3694 - val_accuracy: 0.8176 - val_loss: 0.5685\n",
            "Epoch 21/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.3653 - val_accuracy: 0.8860 - val_loss: 0.4474\n",
            "Epoch 22/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.3665 - val_accuracy: 0.8305 - val_loss: 0.5123\n",
            "Epoch 23/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.3554 - val_accuracy: 0.8883 - val_loss: 0.4271\n",
            "Epoch 24/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.3645 - val_accuracy: 0.8118 - val_loss: 0.5670\n",
            "Epoch 25/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.3604 - val_accuracy: 0.8652 - val_loss: 0.4770\n",
            "Epoch 26/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.3511 - val_accuracy: 0.8505 - val_loss: 0.5184\n",
            "Epoch 27/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.3562 - val_accuracy: 0.7937 - val_loss: 0.6400\n",
            "Epoch 28/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.3603 - val_accuracy: 0.7837 - val_loss: 0.6487\n",
            "Epoch 29/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.3479 - val_accuracy: 0.7946 - val_loss: 0.6014\n",
            "Epoch 30/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.3488 - val_accuracy: 0.8869 - val_loss: 0.4422\n",
            "Epoch 31/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.3448 - val_accuracy: 0.8296 - val_loss: 0.5401\n",
            "Epoch 32/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.3408 - val_accuracy: 0.7795 - val_loss: 0.6385\n",
            "Epoch 33/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.3447 - val_accuracy: 0.8152 - val_loss: 0.5480\n",
            "Epoch 34/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.3367 - val_accuracy: 0.8056 - val_loss: 0.5571\n",
            "Epoch 35/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.3444 - val_accuracy: 0.7994 - val_loss: 0.5853\n",
            "Epoch 36/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.3416 - val_accuracy: 0.8392 - val_loss: 0.5322\n",
            "Epoch 37/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.3452 - val_accuracy: 0.8814 - val_loss: 0.4487\n",
            "Epoch 38/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.3402 - val_accuracy: 0.7866 - val_loss: 0.6526\n",
            "Epoch 39/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.3433 - val_accuracy: 0.7496 - val_loss: 0.7221\n",
            "Epoch 40/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.3258 - val_accuracy: 0.7858 - val_loss: 0.6492\n",
            "Epoch 41/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.3287 - val_accuracy: 0.7792 - val_loss: 0.6715\n",
            "Epoch 42/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.3363 - val_accuracy: 0.7040 - val_loss: 0.7978\n",
            "Epoch 43/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.3233 - val_accuracy: 0.7492 - val_loss: 0.7138\n",
            "Epoch 44/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.3375 - val_accuracy: 0.7874 - val_loss: 0.6381\n",
            "Epoch 45/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.3195 - val_accuracy: 0.7725 - val_loss: 0.6810\n",
            "Epoch 46/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.3247 - val_accuracy: 0.7766 - val_loss: 0.6551\n",
            "Epoch 47/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.3228 - val_accuracy: 0.7554 - val_loss: 0.7118\n",
            "Epoch 48/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.3226 - val_accuracy: 0.6534 - val_loss: 0.9924\n",
            "Epoch 49/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.3276 - val_accuracy: 0.7773 - val_loss: 0.6772\n",
            "Epoch 50/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.3162 - val_accuracy: 0.7856 - val_loss: 0.6390\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=50, batch_size=32)\n"
      ]
    }
  ]
}